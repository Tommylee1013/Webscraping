{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Problem 1 ~ 5\n",
    "\n",
    "Please put IMDB sentiment (positive, negative) of movie review data (`IMDB Dataset.csv`) as a dependent variable. You want to evaluate model accuracy after establishing a model with the sentiment score for the review obtained using the sentiment dictionary(Lexion) as an independent variable. Among the entire data, only the first 500 data are used for convenience. Among these, the first 70% is used as train data to build a model, and the remaining 30% is used as test data to evaluate accuracy. For accuracy evaluation, accuracy (accuracy rate) is used."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9da44e792e017aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, preprocess the review sentence using the following preprocessing way"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e6bf59a4824cc90"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:55:31.439703Z",
     "start_time": "2023-12-13T07:55:30.975426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "review = pd.read_csv('../Data/IMDBDataset.csv')\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Second, find the words that match the words in the NRC dictionary. (using `NRC-Emotion-Lexion-Wordlevel-v0.92.txt` in Sogang Cyber Campus)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61050a8cadb3242d"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/junghunlee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "NRC = pd.read_csv('../Data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', \n",
    "                  engine = \"python\", \n",
    "                  header = None, \n",
    "                  sep = \"\\t\")\n",
    "NRC = NRC[(NRC != 0).all(1)] \n",
    "NRC = NRC.reset_index(drop=True)\n",
    "\n",
    "# data preprocessing\n",
    "tokenizer = RegexpTokenizer('[\\w]+')\n",
    "stop_words = stopwords.words('english')\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "n = 500\n",
    "score_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:55:32.756519Z",
     "start_time": "2023-12-13T07:55:32.301913Z"
    }
   },
   "id": "b98038728d7153bd"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "match_review_lexion = []\n",
    "for row in review['review'][0:n]:\n",
    "    raw = row.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in stop_words] # remove stopwords\n",
    "    match_words = [x for x in stopped_tokens if x in list(NRC[0])] # match w/ lexicon\n",
    "    match_review_lexion.append(match_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:56:02.604879Z",
     "start_time": "2023-12-13T07:55:33.211031Z"
    }
   },
   "id": "1e1aa7e7803870f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 1\n",
    "\n",
    "Regarding 10th review document (index : 9), how many words do match the words in the NRC dictionary?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a2b14b9d4a06fac"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['gut', 'laughter', 'young', 'love', 'hell']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_review_lexion[9]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:56:14.338963Z",
     "start_time": "2023-12-13T07:56:14.326393Z"
    }
   },
   "id": "2740dc59937bfbaf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 2\n",
    "\n",
    "How many positive words are in the 10th review document?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8da04626193afcff"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "positive_words = []\n",
    "negative_words = []\n",
    "n = 500\n",
    "\n",
    "for row in review['review'][0:n]:\n",
    "    raw = row.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in stop_words] # remove stopwords\n",
    "    match_words = [x for x in stopped_tokens if x in list(NRC[0])] # match w/ lexicon\n",
    "\n",
    "    emotion=[]\n",
    "    for i in match_words:\n",
    "        temp = list(NRC.iloc[np.where(NRC[0] == i)[0],1])  # emotion list\n",
    "        for j in temp:\n",
    "            emotion.append(j)\n",
    "    sentiment_result1 = pd.Series(emotion).value_counts()\n",
    "    try: neg = sentiment_result1.negative  # negative word count\n",
    "    except: neg = 0\n",
    "    try: pos = sentiment_result1.positive # positive word count\n",
    "    except: pos = 0\n",
    "    score = pos - neg   \n",
    "    positive_words.append(pos)\n",
    "    negative_words.append(neg)\n",
    "    score_list.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:56:51.245057Z",
     "start_time": "2023-12-13T07:56:15.828856Z"
    }
   },
   "id": "f6b0ad67b37a9707"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words[9]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:57:05.544501Z",
     "start_time": "2023-12-13T07:57:05.526873Z"
    }
   },
   "id": "cd45bdd3dcc89e9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 3\n",
    "\n",
    "How many negative words are in the 10th (index : 9) review document?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26d53f74ecafe5fd"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words[9]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:57:07.296758Z",
     "start_time": "2023-12-13T07:57:07.278807Z"
    }
   },
   "id": "d0248b90e5bc7c91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 4\n",
    "\n",
    "Now, assign scores 1 and -1 to words that match positive and negative words in the NRC dictionary, respectiely. Then, generate the sentiment score by adding the positive and negative scores as an independent variable. Evaluate the (prediction) accuracy of a logistic regression model with the sentiment score obtained using the procedures above"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ee275c15a5104ac"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "500"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:57:49.724259Z",
     "start_time": "2023-12-13T07:57:49.712649Z"
    }
   },
   "id": "6a215b5e4a14fc8c"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "     lexion sentiment\n0       -11  positive\n1        13  positive\n2         4  positive\n3        -3  negative\n4        17  positive\n..      ...       ...\n495      -8  negative\n496       2  negative\n497       1  negative\n498       9  negative\n499      26  positive\n\n[500 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lexion</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-11</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-3</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>-8</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>2</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>1</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>9</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>26</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score = pd.DataFrame([score_list], index = ['lexion']).T\n",
    "df_score = pd.concat([df_score, review.sentiment[:500]], axis = 1)\n",
    "df_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:57:51.932041Z",
     "start_time": "2023-12-13T07:57:51.925403Z"
    }
   },
   "id": "89d5aa3a66e6aae8"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = df_score['lexion'][:350] # 70%\n",
    "X_test = df_score['lexion'][350:] # 30%\n",
    "\n",
    "y_train = df_score['sentiment'][:350]\n",
    "y_test = df_score['sentiment'][350:]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(np.array(X_train).reshape(-1,1), y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:59:40.104569Z",
     "start_time": "2023-12-13T07:59:40.081558Z"
    }
   },
   "id": "a3ce0aebcc2d5816"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.66      0.68        77\n",
      "    positive       0.66      0.68      0.67        73\n",
      "\n",
      "    accuracy                           0.67       150\n",
      "   macro avg       0.67      0.67      0.67       150\n",
      "weighted avg       0.67      0.67      0.67       150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(np.array(X_test).reshape(-1,1))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:00:16.856489Z",
     "start_time": "2023-12-13T08:00:16.836847Z"
    }
   },
   "id": "95279f467212923b"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model test score is  0.673333\n"
     ]
    }
   ],
   "source": [
    "print(f'The model test score is {model.score(np.array(X_test).reshape(-1,1), np.array(y_test)) : .6f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:00:44.451181Z",
     "start_time": "2023-12-13T08:00:44.441860Z"
    }
   },
   "id": "ea7dc1033f93a59e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 5\n",
    "\n",
    "Now, assign scores 2 and -1 to words that match positive and negative words in the NRC dictionary, respectiely. Then, generate the sentiment score by adding the positive and negative scores as an independent variable. Evaluate the (prediction) accuracy of a logistic regression model with the sentiment score obtained using the procedures above"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "536db9b6b11066db"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "n = 500\n",
    "score_list = []\n",
    "\n",
    "for row in review['review'][0:n]:\n",
    "    raw = row.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in stop_words] # remove stopwords\n",
    "    match_words = [x for x in stopped_tokens if x in list(NRC[0])] # match w/ lexicon\n",
    "\n",
    "    emotion=[]\n",
    "    for i in match_words:\n",
    "        temp = list(NRC.iloc[np.where(NRC[0] == i)[0],1])  # emotion list\n",
    "        for j in temp:\n",
    "            emotion.append(j)\n",
    "    sentiment_result1 = pd.Series(emotion).value_counts()\n",
    "    try: neg = sentiment_result1.negative  # negative word count\n",
    "    except: neg = 0\n",
    "    try: pos = sentiment_result1.positive * 2 # positive word count\n",
    "    except: pos = 0\n",
    "    score = pos - neg   \n",
    "    score_list.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:02:08.169960Z",
     "start_time": "2023-12-13T08:01:32.864324Z"
    }
   },
   "id": "e7ee3b7ee23a1025"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "500"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:02:18.517242Z",
     "start_time": "2023-12-13T08:02:18.483490Z"
    }
   },
   "id": "e75973a7ea3c6cc5"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "     lexion sentiment\n0        -1  positive\n1        27  positive\n2        12  positive\n3        -1  negative\n4        36  positive\n..      ...       ...\n495       1  negative\n496       7  negative\n497       7  negative\n498      24  negative\n499      94  positive\n\n[500 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lexion</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>1</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>7</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>7</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>24</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>94</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score = pd.DataFrame([score_list], index = ['lexion']).T\n",
    "df_score = pd.concat([df_score, review.sentiment[:500]], axis = 1)\n",
    "df_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:02:26.328022Z",
     "start_time": "2023-12-13T08:02:26.308876Z"
    }
   },
   "id": "d30c35f8d4714a32"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_score['lexion'][:350] # 70%\n",
    "X_test = df_score['lexion'][350:] # 30%\n",
    "\n",
    "y_train = df_score['sentiment'][:350]\n",
    "y_test = df_score['sentiment'][350:]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(np.array(X_train).reshape(-1,1), y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:02:49.936018Z",
     "start_time": "2023-12-13T08:02:49.907839Z"
    }
   },
   "id": "64e21272b8eaf613"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.73      0.67        77\n",
      "    positive       0.65      0.53      0.59        73\n",
      "\n",
      "    accuracy                           0.63       150\n",
      "   macro avg       0.64      0.63      0.63       150\n",
      "weighted avg       0.64      0.63      0.63       150\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(X_test).reshape(-1,1))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:03:07.296372Z",
     "start_time": "2023-12-13T08:03:07.272216Z"
    }
   },
   "id": "20b75b6f8deb3336"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model test score is  0.633333\n"
     ]
    }
   ],
   "source": [
    "print(f'The model test score is {model.score(np.array(X_test).reshape(-1,1), np.array(y_test)) : .6f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:03:17.774454Z",
     "start_time": "2023-12-13T08:03:17.757583Z"
    }
   },
   "id": "a0fc0fd02de525ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Problem 6 ~ 7\n",
    "\n",
    "Regarding the first 2000 overviews of movie review data (`movies_metadata.csv`), you want to do some analysis for the movie overview. Create a variable 'long', which is 1 if 'run_time' is longer than 100, otherwise, it is 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b827eab2f6bf92"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "   adult                              belongs_to_collection    budget  \\\n0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n1  False                                                NaN  65000000   \n2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n3  False                                                NaN  16000000   \n4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n\n                                              genres  \\\n0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n4                     [{'id': 35, 'name': 'Comedy'}]   \n\n                               homepage     id    imdb_id original_language  \\\n0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n1                                   NaN   8844  tt0113497                en   \n2                                   NaN  15602  tt0113228                en   \n3                                   NaN  31357  tt0114885                en   \n4                                   NaN  11862  tt0113041                en   \n\n                original_title  \\\n0                    Toy Story   \n1                      Jumanji   \n2             Grumpier Old Men   \n3            Waiting to Exhale   \n4  Father of the Bride Part II   \n\n                                            overview  ... release_date  \\\n0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n\n       revenue runtime                                   spoken_languages  \\\n0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n\n     status                                            tagline  \\\n0  Released                                                NaN   \n1  Released          Roll the dice and unleash the excitement!   \n2  Released  Still Yelling. Still Fighting. Still Ready for...   \n3  Released  Friends are the people who let you be yourself...   \n4  Released  Just When His World Is Back To Normal... He's ...   \n\n                         title  video vote_average vote_count  \n0                    Toy Story  False          7.7     5415.0  \n1                      Jumanji  False          6.9     2413.0  \n2             Grumpier Old Men  False          6.5       92.0  \n3            Waiting to Exhale  False          6.1       34.0  \n4  Father of the Bride Part II  False          5.7      173.0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adult</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>id</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>...</th>\n      <th>release_date</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>video</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n      <td>30000000</td>\n      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n      <td>http://toystory.disney.com/toy-story</td>\n      <td>862</td>\n      <td>tt0114709</td>\n      <td>en</td>\n      <td>Toy Story</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>...</td>\n      <td>1995-10-30</td>\n      <td>373554033.0</td>\n      <td>81.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>NaN</td>\n      <td>Toy Story</td>\n      <td>False</td>\n      <td>7.7</td>\n      <td>5415.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>65000000</td>\n      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n      <td>NaN</td>\n      <td>8844</td>\n      <td>tt0113497</td>\n      <td>en</td>\n      <td>Jumanji</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>...</td>\n      <td>1995-12-15</td>\n      <td>262797249.0</td>\n      <td>104.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n      <td>Released</td>\n      <td>Roll the dice and unleash the excitement!</td>\n      <td>Jumanji</td>\n      <td>False</td>\n      <td>6.9</td>\n      <td>2413.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n      <td>0</td>\n      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n      <td>NaN</td>\n      <td>15602</td>\n      <td>tt0113228</td>\n      <td>en</td>\n      <td>Grumpier Old Men</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>...</td>\n      <td>1995-12-22</td>\n      <td>0.0</td>\n      <td>101.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n      <td>Grumpier Old Men</td>\n      <td>False</td>\n      <td>6.5</td>\n      <td>92.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>16000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n      <td>NaN</td>\n      <td>31357</td>\n      <td>tt0114885</td>\n      <td>en</td>\n      <td>Waiting to Exhale</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>...</td>\n      <td>1995-12-22</td>\n      <td>81452156.0</td>\n      <td>127.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Friends are the people who let you be yourself...</td>\n      <td>Waiting to Exhale</td>\n      <td>False</td>\n      <td>6.1</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n      <td>0</td>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n      <td>NaN</td>\n      <td>11862</td>\n      <td>tt0113041</td>\n      <td>en</td>\n      <td>Father of the Bride Part II</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>...</td>\n      <td>1995-02-10</td>\n      <td>76578911.0</td>\n      <td>106.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Just When His World Is Back To Normal... He's ...</td>\n      <td>Father of the Bride Part II</td>\n      <td>False</td>\n      <td>5.7</td>\n      <td>173.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "metadata = pd.read_csv('../Data/movies_metadata.csv', engine = 'python')[:2000]\n",
    "metadata.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:16:31.316468Z",
     "start_time": "2023-12-13T08:16:30.640322Z"
    }
   },
   "id": "c3b4513f86264490"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 6 \n",
    "\n",
    "How many movies are classified as long = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffe09d3e82059811"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "metadata['long'] = 0\n",
    "metadata.loc[metadata['runtime'] > 100, 'long'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:16:32.609631Z",
     "start_time": "2023-12-13T08:16:32.595398Z"
    }
   },
   "id": "809ef82793c59f8c"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "      runtime  long\n0        81.0     0\n1       104.0     1\n2       101.0     1\n3       127.0     1\n4       106.0     1\n...       ...   ...\n1995    103.0     1\n1996     96.0     0\n1997    112.0     1\n1998     86.0     0\n1999     95.0     0\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>runtime</th>\n      <th>long</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>81.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>104.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>101.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>127.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>103.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>96.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>112.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>86.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>95.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[['runtime','long']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:16:33.774121Z",
     "start_time": "2023-12-13T08:16:33.763020Z"
    }
   },
   "id": "35b7d4446adbbd9d"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "1072"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadata[metadata['long'] == 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:16:35.857472Z",
     "start_time": "2023-12-13T08:16:35.838744Z"
    }
   },
   "id": "2d7302dad4eaa83b"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "long\n1    1072\n0     928\nName: count, dtype: int64"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['long'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:16:38.765857Z",
     "start_time": "2023-12-13T08:16:38.744435Z"
    }
   },
   "id": "1c3367b8c9c67428"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 7\n",
    "\n",
    "Construct a logistic regression model with the 'vote_average' in the movie review data as a predictor variable($X$) and the 'long' obtained above as a response variable($y$). Then evaluate the model accuracy. Note that, from the dataset, the first 70% is used as train data to build a model, and the remaining 30% is used as test data to evaluate accuracy. For accuracy evaluation, accuracy (accuracy rate) is used"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef2d40b7028e2b7"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = metadata['vote_average'][:1400] # 70%\n",
    "X_test = metadata['vote_average'][1400:] # 30%\n",
    "\n",
    "y_train = metadata['long'][:1400]\n",
    "y_test = metadata['long'][1400:]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(np.array(X_train).reshape(-1,1), y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:17:32.502073Z",
     "start_time": "2023-12-13T08:17:32.466952Z"
    }
   },
   "id": "922a1a67b478d31"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.33      0.46       309\n",
      "           1       0.56      0.88      0.68       291\n",
      "\n",
      "    accuracy                           0.60       600\n",
      "   macro avg       0.65      0.61      0.57       600\n",
      "weighted avg       0.66      0.60      0.57       600\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(X_test).reshape(-1,1))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:17:46.086544Z",
     "start_time": "2023-12-13T08:17:46.055475Z"
    }
   },
   "id": "2c1ea619b9ccee10"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model test score is  0.600000\n"
     ]
    }
   ],
   "source": [
    "print(f'The model test score is {model.score(np.array(X_test).reshape(-1,1), np.array(y_test)) : .6f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:17:53.599107Z",
     "start_time": "2023-12-13T08:17:53.571697Z"
    }
   },
   "id": "26477bbaa001aa12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Problem 8 ~ 9\n",
    "\n",
    "Regarding the first 2000 overviews of movie review data (`movies_metadata.csv`), you intend to analyze the data using a topic model based on LDA. Here, the max features of the TF-IDF vector are limited to 1000 and applied. Apply the topic model of the sklearn library to find where the first document falls under topics 1 to 7 (index : 0 to 6). Apply (designate 7 topics, random_state = 777, running_method = 'online', max_iter = 5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c16990bf2e0ec348"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['overview'] = metadata['overview'].fillna('')  # fillna(\"\"): delete null\n",
    "metadata['overview'].isnull().sum() #  Null check again"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:21:21.421412Z",
     "start_time": "2023-12-13T08:21:21.391884Z"
    }
   },
   "id": "91b94b681a458887"
  },
  {
   "cell_type": "markdown",
   "source": [
    "data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "262888d9dd15a660"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "overview_list = []\n",
    "\n",
    "for i in range(len(metadata['overview'])):\n",
    "    overview1 = re.sub('[^a-zA-z]',' ',metadata['overview'][i])\n",
    "    overview2 = overview1.lower()\n",
    "    overview_list.append(overview2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:21:54.039191Z",
     "start_time": "2023-12-13T08:21:54.022628Z"
    }
   },
   "id": "f58e87fe44f053ee"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "titles = metadata['original_title']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:22:02.356624Z",
     "start_time": "2023-12-13T08:22:02.318688Z"
    }
   },
   "id": "fbd0d638ff9accc3"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "synopses = [re.sub(r'[^a-zA-Z]', ' ', overview) for overview in metadata['overview']]\n",
    "synopses = [line.lower() for line in synopses]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:22:10.286699Z",
     "start_time": "2023-12-13T08:22:10.268356Z"
    }
   },
   "id": "c04829f58f3fc936"
  },
  {
   "cell_type": "markdown",
   "source": [
    "vectorize using sklearn TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b4b64e15a6d1b8f"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/junghunlee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import urllib.request\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words = 'english', \n",
    "    max_features = 1000\n",
    ")\n",
    "X = vectorizer.fit_transform(synopses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:24:38.528205Z",
     "start_time": "2023-12-13T08:24:38.442056Z"
    }
   },
   "id": "6234099e10e53244"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 572 ms, sys: 4.74 ms, total: 576 ms\n",
      "Wall time: 611 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components = 7, # 7 topics\n",
    "    learning_method = 'online',\n",
    "    random_state = 777,\n",
    "    max_iter = 5\n",
    ")\n",
    "\n",
    "lda_top = lda_model.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:24:51.253341Z",
     "start_time": "2023-12-13T08:24:50.643648Z"
    }
   },
   "id": "b31a1fe9c19d4345"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.03111175, 0.03111176, 0.11279337, 0.03111314, 0.73163452,\n       0.03111188, 0.03112359])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_top[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:27:03.344016Z",
     "start_time": "2023-12-13T08:27:03.332054Z"
    }
   },
   "id": "df7b83055d9a2c60"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 8\n",
    "\n",
    "What is the number of documents belonging to the topic 3 (index : 2) ?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df04a0b0ed9853e0"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.03111175, 0.03111176, 0.11279337, ..., 0.73163452, 0.03111188,\n        0.03112359],\n       [0.03035427, 0.03036649, 0.23805431, ..., 0.61016171, 0.03035436,\n        0.03035414],\n       [0.03235602, 0.03235601, 0.03239337, ..., 0.62125018, 0.0323561 ,\n        0.21693185],\n       ...,\n       [0.02778766, 0.02778755, 0.02791853, ..., 0.83312438, 0.02778772,\n        0.02779088],\n       [0.03038962, 0.03060413, 0.03047763, ..., 0.81735965, 0.03038947,\n        0.03038978],\n       [0.02956066, 0.0295605 , 0.1856207 , ..., 0.66655776, 0.02956071,\n        0.02956312]])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_top"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:29:43.481551Z",
     "start_time": "2023-12-13T08:29:43.462059Z"
    }
   },
   "id": "f69a86ef2d8705c1"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in Topic 3: 352\n"
     ]
    }
   ],
   "source": [
    "dominant_topics = np.argmax(lda_top, axis = 1)\n",
    "topic_count = np.sum(dominant_topics == 2)\n",
    "print(f\"Number of documents in Topic 3: {topic_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:29:27.889372Z",
     "start_time": "2023-12-13T08:29:27.872011Z"
    }
   },
   "id": "ada05c0744829174"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in Topic 1: 24\n",
      "Number of documents in Topic 2: 7\n",
      "Number of documents in Topic 3: 352\n",
      "Number of documents in Topic 4: 8\n",
      "Number of documents in Topic 5: 1601\n",
      "Number of documents in Topic 6: 0\n",
      "Number of documents in Topic 7: 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(7) :\n",
    "    topic_count = np.sum(dominant_topics == i)\n",
    "    print(f\"Number of documents in Topic {i + 1}: {topic_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:31:09.140118Z",
     "start_time": "2023-12-13T08:31:09.119184Z"
    }
   },
   "id": "5442cb39eda0ec5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Problem 9\n",
    "\n",
    "Waht is the top word for topic 2 (index : 1) ?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34afd42cff0259ff"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('violent', 4.36), ('freddy', 4.33), ('president', 3.99), ('lisa', 2.5), ('process', 1.12)]\n",
      "Topic 2: [('space', 5.24), ('power', 2.68), ('mind', 2.5), ('private', 2.15), ('prevent', 1.81)]\n",
      "Topic 3: [('new', 11.12), ('gets', 9.86), ('killer', 9.58), ('man', 9.5), ('angeles', 9.39)]\n",
      "Topic 4: [('government', 6.0), ('alien', 4.74), ('games', 4.05), ('planet', 3.44), ('amy', 3.08)]\n",
      "Topic 5: [('young', 43.61), ('life', 41.83), ('family', 36.41), ('film', 34.72), ('new', 33.55)]\n",
      "Topic 6: [('judge', 0.19), ('jimmy', 0.16), ('park', 0.16), ('crime', 0.16), ('famous', 0.16)]\n",
      "Topic 7: [('max', 8.24), ('alex', 5.88), ('scheme', 4.01), ('steal', 3.38), ('sarah', 3.27)]\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_topics(components, feature_names, n = 5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), \n",
    "              [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "\n",
    "get_topics(lda_model.components_, terms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:28:32.757797Z",
     "start_time": "2023-12-13T08:28:32.718985Z"
    }
   },
   "id": "3987e47fccc9b3d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
