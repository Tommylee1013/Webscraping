{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12af507b351d54",
   "metadata": {},
   "source": [
    "### Text Mining Homework 6\n",
    "\n",
    " Among the entire data of IMDB movie review data (IMDB Dataset.csv), the similarity between the three words and the review document are analyzed by using only review of the first 1000 data after preprocessing procedures as follows\n",
    " \n",
    "A. cat\n",
    "B. hero\n",
    "C. action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:37:45.669090Z",
     "start_time": "2023-12-10T04:37:45.237171Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = pd.read_csv('../Data/IMDBDataset.csv', engine = 'python')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed86c8ddff4b3fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:37:46.304223Z",
     "start_time": "2023-12-10T04:37:46.035103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/pl9tj55n57s9jg28npxw61n80000gn/T/ipykernel_54168/606716564.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  for row in data['review'][0:n] : reviews.append(BeautifulSoup(row, 'html5lib').get_text())\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "reviews = []\n",
    "for row in data['review'][0:n] : reviews.append(BeautifulSoup(row, 'html5lib').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705c61d8009d07a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:37:46.790467Z",
     "start_time": "2023-12-10T04:37:46.774215Z"
    }
   },
   "outputs": [],
   "source": [
    "review_list = []\n",
    "for row1 in reviews : review_list.append(re.sub('[^a-zA-Z]',' ', row1).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b37169a2c574c",
   "metadata": {},
   "source": [
    "#### Problem 1\n",
    "\n",
    "Use `word2vec` (5-gram, CBOW, number of hidden vector elements = 100, minimum word frequency = 5, number of learning processes = 4) from the genism package to report the word most similar to the above three words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59674f8c760f3256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:37:50.094399Z",
     "start_time": "2023-12-10T04:37:49.285142Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences = review_list, \n",
    "    vector_size = 100, \n",
    "    window = 5, \n",
    "    min_count = 5, \n",
    "    workers = 4, \n",
    "    sg = 0\n",
    ")\n",
    "\n",
    "above_words = ['cat','hero','action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25502db30191a4fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:37:53.151889Z",
     "start_time": "2023-12-10T04:37:52.710101Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'cat' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m similar_word \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mabove_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe word most similar to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mabove_words\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilar_word[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with a similarity score of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilar_word[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Webscraping/lib/python3.10/site-packages/gensim/models/keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[0;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[1;32m    844\u001b[0m ]\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/Webscraping/lib/python3.10/site-packages/gensim/models/keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[0;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'cat' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "similar_word = model.wv.most_similar(positive = above_words)\n",
    "print(f\"The word most similar to {above_words} is {similar_word[0][0]} with a similarity score of {similar_word[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cd6683d151162",
   "metadata": {},
   "source": [
    "#### Probelm 2\n",
    "\n",
    "Using `doc2vec` (vector_size = 300, alpha = 0.025, min_alpha = 0.025, workers = 8, window = 8) of the genism package (learning with epoch = 50) to find the document most similar to the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5eb720950e5f607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:37:54.928604Z",
     "start_time": "2023-12-10T04:37:54.923197Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "model = Doc2Vec(\n",
    "    vector_size = 300, \n",
    "    alpha = 0.025, \n",
    "    min_alpha = 0.025, \n",
    "    workers = 8, \n",
    "    window = 8, \n",
    "    epochs = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13f51bb828a16d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:37:55.512765Z",
     "start_time": "2023-12-10T04:37:55.444291Z"
    }
   },
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words = _d, tags = [str(i)]) for i, _d in enumerate(review_list)]\n",
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1415dee3b156091b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:38:05.629127Z",
     "start_time": "2023-12-10T04:37:55.856717Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    tagged_data, \n",
    "    total_examples = model.corpus_count, \n",
    "    epochs = model.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9884e96217a1b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:38:08.943825Z",
     "start_time": "2023-12-10T04:38:08.941249Z"
    }
   },
   "outputs": [],
   "source": [
    "first_doc_vec = model.infer_vector(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d983bb73a1307c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:38:09.440283Z",
     "start_time": "2023-12-10T04:38:09.358199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document most similar to the first document is 296's document whose similarity is 0.1611\n"
     ]
    }
   ],
   "source": [
    "similar_docs = model.dv.most_similar([first_doc_vec], topn = 1)\n",
    "print(f\"Document most similar to the first document is {similar_docs[0][0]}'s document whose similarity is {similar_docs[0][1] :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bfa5cab57b16d1",
   "metadata": {},
   "source": [
    "#### Problem 3\n",
    "\n",
    "Report `doc2vec` of genism package as the most similar document to IMDB Movie Review 1st document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2323d66e75a0658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:38:13.536794Z",
     "start_time": "2023-12-10T04:38:10.308453Z"
    }
   },
   "outputs": [],
   "source": [
    "tagged_documents = [TaggedDocument(words=doc.split(), tags = [str(i)]) for i, doc in enumerate(review_list)]\n",
    "\n",
    "model = Doc2Vec(\n",
    "    vector_size = 100, \n",
    "    window = 8, \n",
    "    min_count = 2, \n",
    "    workers = 8, \n",
    "    epochs = 40\n",
    ")\n",
    "model.build_vocab(tagged_documents)\n",
    "model.train(\n",
    "    tagged_documents, \n",
    "    total_examples = model.corpus_count, \n",
    "    epochs = model.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a83226e10afefe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T04:38:14.114533Z",
     "start_time": "2023-12-10T04:38:14.052827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document most similar to the first document: ('861', 0.2421104460954666)\n"
     ]
    }
   ],
   "source": [
    "vec_first_document = model.infer_vector(review_list)\n",
    "similar_documents = model.dv.most_similar([vec_first_document], topn = 1)\n",
    "print(f\"Document most similar to the first document: {similar_documents[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
