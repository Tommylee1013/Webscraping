{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa097ae26434b247",
   "metadata": {},
   "source": [
    "### Oil Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://oilprice.com/Latest-Energy-News/World-News/Page-\"\n",
    "\n",
    "news_titles = []\n",
    "news_date = []\n",
    "news_writer = []\n",
    "news_excerpt = []\n",
    "\n",
    "for i in range(150):\n",
    "    req = requests.get(url + str(i) + \".html\")\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    title_elements = soup.select(\".categoryArticle__title\")\n",
    "    meta_elements = soup.select(\".categoryArticle__meta\")\n",
    "    excerpt_elements = soup.select('.categoryArticle__excerpt')\n",
    "\n",
    "    for title_element in title_elements:\n",
    "        title = title_element.text.strip()\n",
    "        news_titles.append(title)\n",
    "\n",
    "    for meta_element in meta_elements:\n",
    "        time, writer = meta_element.text.strip().split(' | ')\n",
    "        date, _ = time.split(' at ')\n",
    "        news_writer.append(writer)\n",
    "        news_date.append(date)\n",
    "\n",
    "    for excerpt_element in excerpt_elements:\n",
    "        excerpt = excerpt_element.text.strip()\n",
    "        news_excerpt.append(excerpt)\n",
    "\n",
    "news = pd.DataFrame([news_titles, news_writer, news_excerpt],\n",
    "                    columns = news_date,\n",
    "                    index = ['title', 'writer', 'excerpt']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b8d058781aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8424446a9caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.index = pd.to_datetime(news.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2d4a2004ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7f6e09b7a8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # FutureWarning 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6444d10f1122d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiments = pd.DataFrame(columns = [\"Date\", \"Positive\", \"Negative\", \"Neutral\"])\n",
    "unique_dates = news.index.unique()\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336d9799bf41ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_date = news[\"title\"].tolist()\n",
    "\n",
    "tokenized_texts = [\n",
    "        [word for word in tokenizer.tokenize(text) if word.lower() not in stop_words]\n",
    "        for text in text_for_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985f5169686f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e1d146307e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(max(tokenized_texts, key = len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2419038317fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "for date in unique_dates:    \n",
    "    #text_for_date = data[data[\"rgs_dt\"] == date][\"news_smy_ifo\"].tolist()\n",
    "    text_for_date = news[news.index == date][\"title\"].tolist()\n",
    "\n",
    "    tokenized_texts = [\n",
    "        [word for word in tokenizer.tokenize(text) if word.lower() not in stop_words]\n",
    "        for text in text_for_date\n",
    "    ]\n",
    "\n",
    "    max_token_length = 150\n",
    "\n",
    "    tokenized_texts = [\" \".join(tokens[:max_token_length]) for tokens in tokenized_texts]\n",
    "    inputs = tokenizer(tokenized_texts, padding = True, truncation = True, return_tensors = \"pt\", max_length = max_token_length)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    positive_prob = probabilities[:, 2].mean().item()\n",
    "    negative_prob = probabilities[:, 0].mean().item()\n",
    "    neutral_prob = probabilities[:, 1].mean().item()\n",
    "    \n",
    "    daily_sentiments = pd.concat([daily_sentiments, \n",
    "                                  pd.DataFrame({\"Date\": date, \n",
    "                                                \"Positive\": positive_prob, \n",
    "                                                \"Negative\": negative_prob, \n",
    "                                                \"Neutral\": neutral_prob}, index = ['0'])],\n",
    "                                 ignore_index = True)\n",
    "\n",
    "daily_sentiments.index = daily_sentiments.Date\n",
    "daily_sentiments = daily_sentiments.iloc[:,1:]\n",
    "daily_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfddc31254a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiments_excerpt = pd.DataFrame(columns = [\"Date\", \"Positive\", \"Negative\", \"Neutral\"])\n",
    "\n",
    "text_for_date = news[\"excerpt\"].tolist()\n",
    "\n",
    "tokenized_texts = [\n",
    "        [word for word in tokenizer.tokenize(text) if word.lower() not in stop_words]\n",
    "        for text in text_for_date]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "for date in unique_dates:    \n",
    "    #text_for_date = data[data[\"rgs_dt\"] == date][\"news_smy_ifo\"].tolist()\n",
    "    text_for_date = news[news.index == date][\"excerpt\"].tolist()\n",
    "\n",
    "    tokenized_texts = [\n",
    "        [word for word in tokenizer.tokenize(text) if word.lower() not in stop_words]\n",
    "        for text in text_for_date\n",
    "    ]\n",
    "\n",
    "    max_token_length = 500\n",
    "\n",
    "    tokenized_texts = [\" \".join(tokens[:max_token_length]) for tokens in tokenized_texts]\n",
    "    inputs = tokenizer(tokenized_texts, padding = True, truncation = True, return_tensors = \"pt\", max_length = max_token_length)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    positive_prob = probabilities[:, 2].mean().item()\n",
    "    negative_prob = probabilities[:, 0].mean().item()\n",
    "    neutral_prob = probabilities[:, 1].mean().item()\n",
    "    \n",
    "    daily_sentiments_excerpt = pd.concat([daily_sentiments_excerpt, \n",
    "                                          pd.DataFrame({\"Date\": date, \n",
    "                                                        \"Positive\": positive_prob, \n",
    "                                                        \"Negative\": negative_prob, \n",
    "                                                        \"Neutral\": neutral_prob}, index = ['0'])],\n",
    "                                 ignore_index = True)\n",
    "\n",
    "daily_sentiments_excerpt.index = daily_sentiments_excerpt.Date\n",
    "daily_sentiments_excerpt = daily_sentiments_excerpt.iloc[:,1:]\n",
    "daily_sentiments_excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cefd29ee0933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiments['sentimental_score'] = daily_sentiments['Positive'] - daily_sentiments['Negative'] + daily_sentiments['Neutral'] * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da659e52069358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(daily_sentiments['sentimental_score'], bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9a1ca5850527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiments_excerpt['sentimental_score'] = daily_sentiments_excerpt['Positive'] - daily_sentiments_excerpt['Negative'] + daily_sentiments_excerpt['Neutral'] * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7ca15fc064405",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(daily_sentiments_excerpt['sentimental_score'], bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aed5be898486a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_sentiments_excerpt.to_csv('excerpt_sentimental.csv')\n",
    "# daily_sentiments.to_csv('title_sentimental.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
